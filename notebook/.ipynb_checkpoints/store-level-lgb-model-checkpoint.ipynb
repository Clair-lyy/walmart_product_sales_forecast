{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9ae186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tqdm\n",
    "import re\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess, CalendarFourier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import gc\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from typing import Union\n",
    "from tqdm.notebook import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e14a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2',  'TX_3', 'WI_1', 'WI_2', 'WI_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5a57f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nweight_df = pd.read_csv('../data/weight_df.csv')\\nweight_df.rename({'0': 'weight'}, axis=1, inplace=True)\\nweight_dict = {\\n    f'{item_id}_{store_id}_evaluation': weight for item_id, store_id, weight in weight_df.values\\n}\\nweight_dict\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "weight_df = pd.read_csv('../data/weight_df.csv')\n",
    "weight_df.rename({'0': 'weight'}, axis=1, inplace=True)\n",
    "weight_dict = {\n",
    "    f'{item_id}_{store_id}_evaluation': weight for item_id, store_id, weight in weight_df.values\n",
    "}\n",
    "weight_dict\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93039c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRMSSEEvaluator(object):\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, \n",
    "                 calendar: pd.DataFrame, prices: pd.DataFrame):\n",
    "        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n",
    "        train_target_columns = train_y.columns.tolist()\n",
    "        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        train_df['all_id'] = 'all'  # for lv1 aggregation\n",
    "\n",
    "        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')]\\\n",
    "                     .columns.tolist()\n",
    "        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')]\\\n",
    "                               .columns.tolist()\n",
    "        \n",
    "        #valid_target_columns = valid_df.columns.tolist()\n",
    "\n",
    "        if not all([c in valid_df.columns for c in id_columns]):\n",
    "            valid_df = pd.concat([train_df[id_columns], valid_df], \n",
    "                                 axis=1, sort=False)\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "\n",
    "        self.weight_columns = weight_columns\n",
    "        self.id_columns = id_columns\n",
    "        self.valid_target_columns = valid_target_columns\n",
    "\n",
    "        weight_df = self.get_weight_df()\n",
    "\n",
    "        self.group_ids = (\n",
    "            'all_id',\n",
    "            'state_id',\n",
    "            'store_id',\n",
    "            'cat_id',\n",
    "            'dept_id',\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            'item_id',\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "        )\n",
    "\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids)):\n",
    "            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n",
    "            scale = []\n",
    "            for _, row in train_y.iterrows():\n",
    "                series = row.values[np.argmax(row.values != 0):]\n",
    "                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n",
    "            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n",
    "            setattr(self, f'lv{i + 1}_train_df', train_y)\n",
    "            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)\\\n",
    "                    [valid_target_columns].sum())\n",
    "\n",
    "            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n",
    "            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n",
    "\n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n",
    "        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns]\\\n",
    "                    .set_index(['item_id', 'store_id'])\n",
    "        weight_df = weight_df.stack().reset_index()\\\n",
    "                   .rename(columns={'level_2': 'd', 0: 'value'})\n",
    "        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n",
    "\n",
    "        weight_df = weight_df.merge(self.prices, how='left',\n",
    "                                    on=['item_id', 'store_id', 'wm_yr_wk'])\n",
    "        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n",
    "        weight_df = weight_df.set_index(['item_id', 'store_id', 'd'])\\\n",
    "                    .unstack(level=2)['value']\\\n",
    "                    .loc[zip(self.train_df.item_id, self.train_df.store_id), :]\\\n",
    "                    .reset_index(drop=True)\n",
    "        weight_df = pd.concat([self.train_df[self.id_columns],\n",
    "                               weight_df], axis=1, sort=False)\n",
    "        return weight_df\n",
    "\n",
    "    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        valid_y = getattr(self, f'lv{lv}_valid_df')\n",
    "        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n",
    "        scale = getattr(self, f'lv{lv}_scale')\n",
    "        return (score / scale).map(np.sqrt) \n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, \n",
    "                                       np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape \\\n",
    "               == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, \n",
    "                                       columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], \n",
    "                                 valid_preds], axis=1, sort=False)\n",
    "\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "\n",
    "            valid_preds_grp = valid_preds.groupby(group_id)[self.valid_target_columns].sum()\n",
    "            setattr(self, f'lv{i + 1}_valid_preds', valid_preds_grp)\n",
    "            \n",
    "            lv_scores = self.rmsse(valid_preds_grp, i + 1)\n",
    "            setattr(self, f'lv{i + 1}_scores', lv_scores)\n",
    "            \n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, \n",
    "                                  sort=False).prod(axis=1)\n",
    "            \n",
    "            all_scores.append(lv_scores.sum())\n",
    "            \n",
    "        self.all_scores = all_scores\n",
    "\n",
    "        return np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c55ec0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wrmsse_score(train_df, pred_df, split_day):\n",
    "    delta = 1941 - split_day\n",
    "    train_fold_df = train_df.iloc[:, : -delta]\n",
    "    if delta == 28:\n",
    "        valid_fold_df = train_df.iloc[:, -delta:]\n",
    "    else:\n",
    "        valid_fold_df = train_df.iloc[:, -delta: -delta+28]\n",
    "\n",
    "    pred_df.rename({f'F{i}': f'd_{split_day+i}' for i in range(1,29)}, axis=1, inplace=True)\n",
    "\n",
    "    pred_df = submission[['id']].merge(pred_df, on = 'id')\n",
    "\n",
    "    evaluator = WRMSSEEvaluator(train_fold_df, valid_fold_df, calendar, prices)\n",
    "    return evaluator.score(pred_df[[col for col in pred_df.columns if re.match('d_\\d{1,4}', col)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fcef93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/sales_train_evaluation.csv')\n",
    "calendar = pd.read_csv('../data/calendar.csv')\n",
    "prices = pd.read_csv('../data/sell_prices.csv')\n",
    "submission = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce18bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "lgb_params = {\n",
    "    #\"boosting_type\": \"goss\",\n",
    "    \"n_estimators\": 500,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"tweedie\",\n",
    "    \"tweedie_variance_power\": 1.1,\n",
    "    \"metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    #\"num_leaves\": 2 ** 5 - 1,\n",
    "    #\"min_data_in_leaf\": 2 ** 12 - 1,\n",
    "    \"feature_fraction\": 0.5,\n",
    "    #\"max_bin\": 100,\n",
    "    \"boost_from_average\": False,\n",
    "    #\"num_boost_round\": 1400,\n",
    "    \"verbose\": -1,\n",
    "    #\"num_threads\": os.cpu_count(),\n",
    "    \"force_row_wise\": True,\n",
    "    \"seed\": 42\n",
    "}\n",
    "'''\n",
    "\n",
    "lgb_params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'tweedie',\n",
    "            'tweedie_variance_power': 1.1,\n",
    "            'metric': 'rmse',\n",
    "             #'subsample': 0.5,\n",
    "             #'subsample_freq': 1,\n",
    "            'learning_rate': 0.03,\n",
    "            'num_leaves': 2 ** 11 - 1,\n",
    "            'min_data_in_leaf': 2 ** 12 - 1,\n",
    "            'feature_fraction': 0.5,\n",
    "            'max_bin': 100,\n",
    "            'boost_from_average': False,\n",
    "            'num_boost_round': 1400,\n",
    "            'verbose': -1,\n",
    "            'num_threads': os.cpu_count(),\n",
    "            'force_row_wise': True,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a55cc7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multistep_target(df, steps):\n",
    "    return pd.DataFrame(\n",
    "        {f'F{i}': df.groupby('id').sales.shift(-i)\n",
    "         for i in range(1, steps+1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f9ef9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] num_iterations is set=1400, num_boost_round=1400 will be ignored. Current value: num_iterations=1400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4095, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3214bcb01464af0bfa76191ff8f35f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRMSSE: 0.36786\n",
      "CA_1 done\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] num_iterations is set=1400, num_boost_round=1400 will be ignored. Current value: num_iterations=1400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4095, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db312d77e774202858c928fb747a27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRMSSE: 0.41210\n",
      "CA_2 done\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] num_iterations is set=1400, num_boost_round=1400 will be ignored. Current value: num_iterations=1400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4095, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd11fa8720349c1affe6227d2830f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRMSSE: 0.37316\n",
      "CA_3 done\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] num_iterations is set=1400, num_boost_round=1400 will be ignored. Current value: num_iterations=1400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4095, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b434ff0ca24779a97e868f9936c9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRMSSE: 0.49820\n",
      "CA_4 done\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] num_iterations is set=1400, num_boost_round=1400 will be ignored. Current value: num_iterations=1400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4095, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85689db20be140d9bd583c60f0479d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRMSSE: 0.46647\n",
      "TX_1 done\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] num_iterations is set=1400, num_boost_round=1400 will be ignored. Current value: num_iterations=1400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4095, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "facbbe7f6a834b7ebc3c58a4639d9592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRMSSE: 0.39868\n",
      "TX_2 done\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] num_iterations is set=1400, num_boost_round=1400 will be ignored. Current value: num_iterations=1400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4095, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe263c92dca4de298f5232e4d083adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRMSSE: 0.51876\n",
      "TX_3 done\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] num_iterations is set=1400, num_boost_round=1400 will be ignored. Current value: num_iterations=1400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4095, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0d6fc994d64edf9706502a29124123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRMSSE: 0.38263\n",
      "WI_1 done\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] num_iterations is set=1400, num_boost_round=1400 will be ignored. Current value: num_iterations=1400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4095, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbe0d877a8a4c20af917d99da0cb666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRMSSE: 0.55377\n",
      "WI_2 done\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] num_iterations is set=1400, num_boost_round=1400 will be ignored. Current value: num_iterations=1400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4095, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1613a00a0c4b0fb777291b83102ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRMSSE: 0.41407\n",
      "WI_3 done\n",
      "CPU times: user 11d 20h 31min 21s, sys: 5d 11h 15min 43s, total: 17d 7h 47min 4s\n",
      "Wall time: 5d 20h 47min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_subs = pd.DataFrame()\n",
    "for store_id in groups:\n",
    "    feature_df = pd.read_feather(f'../data/store_data/grid_full_store_{store_id}_1941_to_1948.feather')\n",
    "    store_train_data = train_data[train_data.store_id==store_id]\n",
    "    \n",
    "    target_df = make_multistep_target(feature_df, 28)\n",
    "    \n",
    "    full_df = pd.concat([feature_df, target_df], axis=1)\n",
    "    \n",
    "    train_df = full_df[full_df['d']<=1913]\n",
    "    \n",
    "    X_columns = train_df.columns.drop(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])\\\n",
    "                    .drop(target_df.columns).drop(['event_name_1','event_type_1','event_name_2','event_type_2'])\n",
    "    \n",
    "    X = train_df[X_columns].fillna(0)\n",
    "    y = train_df[target_df.columns]\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=False)\n",
    "\n",
    "    #model = LinearRegression()\n",
    "    #model.fit(X, y, sample_weight=sample_weights.values)\n",
    "    \n",
    "    model = MultiOutputRegressor(lgb.LGBMRegressor(**lgb_params))\n",
    "    model.fit(X, y)\n",
    "\n",
    "    #y_fit = pd.DataFrame(model.predict(X_train), index=X_train.index, columns=y.columns)\n",
    "    #y_pred = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns)\n",
    "    \n",
    "    #train_rmse = mean_squared_error(y_train, y_fit, squared=False)\n",
    "    #test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    #print((f\"Train RMSE: {train_rmse:.2f}\\n\" f\"Test RMSE: {test_rmse:.2f}\"))\n",
    "    \n",
    "    y_fore = pd.DataFrame(model.predict(full_df[full_df.d==1941][X_columns]), columns=target_df.columns)\n",
    "    y_fore = y_fore.clip(0)\n",
    "    y_fore['id'] = full_df[full_df.d==1941].reset_index().id\n",
    "    \n",
    "    y_valid = pd.DataFrame(model.predict(full_df[full_df.d==1913][X_columns]), columns=target_df.columns)\n",
    "    y_valid = y_valid.clip(0)\n",
    "    y_valid['id']  = full_df[full_df.d==1941].reset_index().id\n",
    "    y_valid['id'] = y_valid['id'].apply(lambda x: x.replace('_evaluation', '_validation'))\n",
    "    \n",
    "    all_sub = pd.concat([y_valid, y_fore], axis=0)\n",
    "    all_sub.to_csv(f'../result/cat_and_store/lgb_{store_id}_submission.csv', index=False)\n",
    "    \n",
    "    all_subs = pd.concat([all_sub, all_subs], axis=0)\n",
    "    \n",
    "    wrmsse_score = get_wrmsse_score(store_train_data.reset_index(), y_valid, 1913)\n",
    "    print(f\"WRMSSE: {wrmsse_score:.5f}\")\n",
    "    \n",
    "    print(f'{store_id} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a30d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs.to_csv(f'../result/lgb_store_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc4fb053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5bf3b0da6d424ca6c27bfd2b64b1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRMSSE: 0.39572\n"
     ]
    }
   ],
   "source": [
    "all_subs['is_valid'] = all_subs.id.apply(lambda x: 1 if '_validation' in x else 0)\n",
    "pred_data = all_subs[all_subs['is_valid']==1].reset_index()\n",
    "\n",
    "wrmsse_score = get_wrmsse_score(train_data, pred_data, 1913)\n",
    "print(f\"WRMSSE: {wrmsse_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42dd33b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.00131256e-05, 2.11836142e-06, 1.26781530e-05, ...,\n",
       "       7.76376791e-07, 1.40868366e-06, 7.76376791e-07])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "169ebb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(np.mean([estimator.feature_importances_ for estimator in model.estimators_], axis=0), index=X_columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "213ea2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enc_item_id_std     89695.071429\n",
       "d                   85629.785714\n",
       "enc_item_id_mean    83978.642857\n",
       "tm_w                82800.142857\n",
       "tm_d                64432.357143\n",
       "release             61290.535714\n",
       "rolling_std_180     55818.928571\n",
       "rolling_mean_180    53205.285714\n",
       "rolling_std_60      46744.178571\n",
       "price_momentum_m    45408.714286\n",
       "rolling_mean_60     45042.107143\n",
       "price_std           43160.785714\n",
       "item_nunique        42746.821429\n",
       "rolling_std_30      42138.500000\n",
       "price_max_cent      37710.714286\n",
       "price_min_cent      37326.000000\n",
       "rolling_std_14      34405.285714\n",
       "rolling_mean_30     34343.000000\n",
       "moon                34121.892857\n",
       "price_min           33872.892857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee51dfae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
